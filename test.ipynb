{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['020', 'png']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"020.png\".split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:12<00:00,  4.44it/s]\n",
      "100%|██████████| 45/45 [00:08<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "image_path = \"data/train/hazy/\"\n",
    "image_list = os.listdir(image_path)\n",
    "histograms = []\n",
    "for image_name in tqdm(image_list[66:121]):\n",
    "    image = cv2.imread(image_path + image_name)\n",
    "    R, G, B = cv2.split(image)\n",
    "    hist, _ = np.histogram(R, bins=251, range=[0, 250])\n",
    "    histograms.append(hist / np.sum(hist))\n",
    "\n",
    "# Summarize the histograms\n",
    "sum_histogram = np.mean(histograms, axis=0)\n",
    "for image_name in tqdm(image_list[121:]):\n",
    "    image = cv2.imread(image_path + image_name)\n",
    "    R, G, B = cv2.split(image)\n",
    "    hist, _ = np.histogram(R, bins=251, range=[0, 250])\n",
    "    histograms.append(hist / np.sum(hist))\n",
    "\n",
    "# Summarize the histograms\n",
    "sum_histogram1 = np.mean(histograms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0492]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "model = torchvision.models.swin_v2_b()\n",
    "model.head = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvnextv2_huge.fcmae\u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, features_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# Load the model\n",
    "model = timm.create_model(\"convnextv2_huge.fcmae\", pretrained=True, features_only=True)\n",
    "import torch\n",
    "\n",
    "x = torch.rand(1, 3, 256, 256)\n",
    "o = model(x)\n",
    "for f in o:\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonwe1e/miniconda3/envs/cv/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1707032588986/work/aten/src/ATen/native/TensorShape.cpp:3559.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769ae9013bfa488b8df6c9bfb4f1c2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.create_model(\n",
    "    \"swinv2_small_window8_256\", pretrained=True, features_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
